{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "565fc24a-7665-433c-835d-bf6544dad152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERADOR DE FEATURES PARA DETECCIÓN DE VIRALIDAD\n",
    "# ===================================================\n",
    "\n",
    "# IMPORTACIONES Y CONFIGURACIÓN INICIAL\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import pytesseract\n",
    "import isodate\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "# Configuración para Tesseract Windows:\n",
    "# pytesseract.pytesseract.tesseract_cmd = r\"C:\\\\Program Files\\\\Tesseract-OCR\\\\tesseract.exe\"\n",
    "\n",
    "\n",
    "# Activar barra de progreso en pandas\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5f12f93d-664a-4828-9559-4ee66a2d0c14",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:4: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:4: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\disan\\AppData\\Local\\Temp\\ipykernel_22476\\4272704594.py:4: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  ruta = \"Scripts\\datos_yt\\youtube_trending_videos_global.csv\"\n",
      "C:\\Users\\disan\\AppData\\Local\\Temp\\ipykernel_22476\\4272704594.py:10: DtypeWarning: Columns (13,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\disan\\AppData\\Local\\Temp\\ipykernel_22476\\4272704594.py:10: DtypeWarning: Columns (13,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\disan\\AppData\\Local\\Temp\\ipykernel_22476\\4272704594.py:10: DtypeWarning: Columns (13,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\disan\\AppData\\Local\\Temp\\ipykernel_22476\\4272704594.py:10: DtypeWarning: Columns (13,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\disan\\AppData\\Local\\Temp\\ipykernel_22476\\4272704594.py:10: DtypeWarning: Columns (13,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\disan\\AppData\\Local\\Temp\\ipykernel_22476\\4272704594.py:10: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\disan\\AppData\\Local\\Temp\\ipykernel_22476\\4272704594.py:10: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\disan\\AppData\\Local\\Temp\\ipykernel_22476\\4272704594.py:10: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\disan\\AppData\\Local\\Temp\\ipykernel_22476\\4272704594.py:10: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
      "C:\\Users\\disan\\AppData\\Local\\Temp\\ipykernel_22476\\4272704594.py:10: DtypeWarning: Columns (24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(ruta, chunksize=chunksize):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cargado con 11371 vídeos únicos de canales pequeños (< 20.000 suscriptores)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Ruta al archivo original grande\n",
    "ruta = \"Scripts\\datos_yt\\youtube_trending_videos_global.csv\"\n",
    "\n",
    "# Leer por chunks para no saturar la memoria\n",
    "chunksize = 100_000\n",
    "filtrados = []\n",
    "\n",
    "for chunk in pd.read_csv(ruta, chunksize=chunksize):\n",
    "    # Filtrar canales con menos de 20.000 suscriptores\n",
    "    chunk_filtrado = chunk[chunk[\"channel_subscriber_count\"] < 20000]\n",
    "    filtrados.append(chunk_filtrado)\n",
    "\n",
    "# Unir todos los trozos filtrados\n",
    "df = pd.concat(filtrados, ignore_index=True)\n",
    "\n",
    "# Eliminar duplicados por video_id, conservando el primero\n",
    "df = df.drop_duplicates(subset=\"video_id\", keep=\"first\")\n",
    "\n",
    "print(f\"Dataset cargado con {len(df)} vídeos únicos de canales pequeños (< 20.000 suscriptores)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c5dbe0fc-f83a-4b68-9475-785b4b5ac02e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['video_id', 'video_published_at', 'video_trending__date', 'video_trending_country', 'channel_id', 'video_title', 'video_description', 'video_default_thumbnail', 'video_category_id', 'video_tags', 'video_duration', 'video_dimension', 'video_definition', 'video_licensed_content', 'video_view_count', 'video_like_count', 'video_comment_count', 'channel_title', 'channel_description', 'channel_custom_url', 'channel_published_at', 'channel_country', 'channel_view_count', 'channel_subscriber_count', 'channel_have_hidden_subscribers', 'channel_video_count', 'channel_localized_title', 'channel_localized_description']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6b46a070-9d1c-4d61-bfca-fa621caf602b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCIONES AUXILIARES\n",
    "\n",
    "def duration_to_seconds(d):\n",
    "    try:\n",
    "        return isodate.parse_duration(d).total_seconds()\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "def uppercase_ratio(text):\n",
    "    text = str(text)\n",
    "    if len(text) == 0:\n",
    "        return 0\n",
    "    upper = sum(1 for c in text if c.isupper())\n",
    "    return upper / len(text)\n",
    "\n",
    "def has_links(text):\n",
    "    return any(x in str(text).lower() for x in [\"http\", \"www\", \"bit.ly\", \"youtu.be\"])\n",
    "\n",
    "def convertir_a_hq(url):\n",
    "    if isinstance(url, str) and \"/default.jpg\" in url:\n",
    "        return url.replace(\"/default.jpg\", \"/hqdefault.jpg\")\n",
    "    return url\n",
    "\n",
    "def download_image(url):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=5)\n",
    "        img = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "        return img\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def preprocess_for_ocr(img_pil):\n",
    "    try:\n",
    "        img_gray = img_pil.convert(\"L\")\n",
    "        img_np = np.array(img_gray)\n",
    "        _, img_thresh = cv2.threshold(img_np, 120, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n",
    "        return Image.fromarray(img_thresh)\n",
    "    except:\n",
    "        return img_pil\n",
    "\n",
    "def count_text(img_pil):\n",
    "    try:\n",
    "        img_preprocessed = preprocess_for_ocr(img_pil)\n",
    "        text = pytesseract.image_to_string(img_preprocessed)\n",
    "        return len(text.strip().split())\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def calculate_colorfulness(img_pil):\n",
    "    try:\n",
    "        img = np.array(img_pil)\n",
    "        (B, G, R) = cv2.split(img.astype(\"float\"))\n",
    "        rg = np.absolute(R - G)\n",
    "        yb = np.absolute(0.5 * (R + G) - B)\n",
    "        std_rg, std_yb = np.std(rg), np.std(yb)\n",
    "        mean_rg, mean_yb = np.mean(rg), np.mean(yb)\n",
    "        return np.sqrt(std_rg**2 + std_yb**2) + (0.3 * np.sqrt(mean_rg**2 + mean_yb**2))\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "def detectar_caras_en_url(url_imagen):\n",
    "    try:\n",
    "        resp = requests.get(url_imagen, stream=True, timeout=5)\n",
    "        if resp.status_code != 200:\n",
    "            return -1\n",
    "        imagen_array = np.asarray(bytearray(resp.content), dtype=np.uint8)\n",
    "        imagen = cv2.imdecode(imagen_array, cv2.IMREAD_COLOR)\n",
    "        if imagen is None:\n",
    "            return -1\n",
    "        gris = cv2.cvtColor(imagen, cv2.COLOR_BGR2GRAY)\n",
    "        face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
    "        caras = face_cascade.detectMultiScale(gris, scaleFactor=1.1, minNeighbors=5)\n",
    "        return len(caras)\n",
    "    except:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "790d6320-86d7-45cb-a98d-9d2b4f831e1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [00:00<00:00, 1658786.55it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [00:00<00:00, 898739.91it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [00:00<00:00, 1884519.95it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [00:00<00:00, 623394.65it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [00:00<00:00, 284309.16it/s]\n",
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [00:00<00:00, 1601579.33it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [00:00<00:00, 116464.35it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [00:00<00:00, 724229.82it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [00:00<00:00, 179279.74it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [40:57<00:00,  4.63it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [43:09<00:00,  4.39it/s]\n",
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 11371/11371 [48:23<00:00,  3.92it/s]\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACIONES Y FEATURES DERIVADAS\n",
    "\n",
    "# Procesar URLs de miniatura\n",
    "if \"thumbnail_url_hq\" not in df.columns:\n",
    "    df[\"thumbnail_url_hq\"] = df[\"video_default_thumbnail\"].apply(convertir_a_hq)\n",
    "\n",
    "# Texto\n",
    "df[\"title_length\"] = df[\"video_title\"].astype(str).progress_apply(len)\n",
    "df[\"title_word_count\"] = df[\"video_title\"].astype(str).progress_apply(lambda x: len(x.split()))\n",
    "df[\"title_has_exclamation\"] = df[\"video_title\"].astype(str).progress_apply(lambda x: \"!\" in x)\n",
    "df[\"title_has_question\"] = df[\"video_title\"].astype(str).progress_apply(lambda x: \"?\" in x)\n",
    "df[\"title_uppercase_ratio\"] = df[\"video_title\"].astype(str).progress_apply(uppercase_ratio)\n",
    "df[\"description_length\"] = df[\"video_description\"].astype(str).progress_apply(len)\n",
    "df[\"has_external_links\"] = df[\"video_description\"].astype(str).progress_apply(has_links)\n",
    "df[\"tag_count\"] = df[\"video_tags\"].astype(str).progress_apply(lambda x: len(x.split(\",\")) if pd.notnull(x) else 0)\n",
    "\n",
    "# Tiempo\n",
    "df[\"published_at\"] = pd.to_datetime(df[\"video_published_at\"], errors=\"coerce\")\n",
    "df[\"hour_of_day\"] = df[\"published_at\"].dt.hour\n",
    "df[\"day_of_week\"] = df[\"published_at\"].dt.weekday\n",
    "df[\"is_weekend\"] = df[\"day_of_week\"].isin([5, 6])\n",
    "df[\"is_peak_hour\"] = df[\"hour_of_day\"].between(15, 17)\n",
    "\n",
    "# Duración\n",
    "df[\"video_duration_sec\"] = df[\"video_duration\"].progress_apply(duration_to_seconds)\n",
    "\n",
    "# Miniatura\n",
    "df[\"thumbnail_text_count\"] = df[\"thumbnail_url_hq\"].progress_apply(lambda x: count_text(download_image(x)))\n",
    "df[\"thumbnail_colorfulness\"] = df[\"thumbnail_url_hq\"].progress_apply(lambda x: calculate_colorfulness(download_image(x)))\n",
    "df[\"thumbnail_faces_count\"] = df[\"thumbnail_url_hq\"].progress_apply(detectar_caras_en_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "948d662b-b34e-4c8b-9e5f-6fcfb277df7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"views_per_second\"] = df[\"video_view_count\"] / (df[\"video_duration_sec\"] + 1)\n",
    "df[\"likes_per_view\"] = df[\"video_like_count\"] / (df[\"video_view_count\"] + 1)\n",
    "df[\"likes_per_sub\"] = df[\"video_like_count\"] / (df[\"channel_subscriber_count\"] + 1)\n",
    "df[\"views_per_sub\"] = df[\"video_view_count\"] / (df[\"channel_subscriber_count\"] + 1)\n",
    "df[\"viral_score\"] = df[\"views_per_sub\"] + df[\"likes_per_view\"] + df[\"likes_per_sub\"]\n",
    "df[\"is_viral\"] = (df[\"views_per_sub\"] > 1.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "35af40fe-7ae5-4c9b-bf77-7a11913fda95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset guardado como 'videos_virales_final.csv'\n"
     ]
    }
   ],
   "source": [
    "ordered_cols = [\n",
    "\"video_id\", \"video_published_at\", \"channel_id\", \"video_title\", \"video_description\", \"video_default_thumbnail\",\n",
    "\"video_category_id\", \"video_tags\", \"video_duration\", \"video_definition\", \"video_view_count\", \"video_like_count\",\n",
    "\"video_comment_count\", \"channel_title\", \"channel_published_at\", \"channel_subscriber_count\", \"channel_video_count\",\n",
    "\"thumbnail_url_hq\", \"thumbnail_faces_count\", \"title_length\", \"title_word_count\", \"title_has_exclamation\",\n",
    "\"title_has_question\", \"title_has_keywords\", \"title_uppercase_ratio\", \"description_length\", \"has_external_links\",\n",
    "\"tag_count\", \"video_duration_sec\", \"published_at\", \"hour_of_day\", \"day_of_week\", \"is_weekend\", \"is_peak_hour\",\n",
    "\"thumbnail_text_count\", \"thumbnail_colorfulness\", \"is_viral\", \"viral_score\", \"views_per_second\",\n",
    "\"likes_per_view\", \"likes_per_sub\", \"views_per_sub\"\n",
    "]\n",
    "\n",
    "df = df[[col for col in ordered_cols if col in df.columns]]\n",
    "\n",
    "# Exportar\n",
    "output_csv = \"videos_virales_final.csv\"\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"Dataset guardado como '{output_csv}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
